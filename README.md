# Web Scraping Collection ğŸ•·ï¸

A comprehensive collection of web scraping scripts for extracting data from popular websites. This project demonstrates various web scraping techniques using Python and provides ready-to-use scripts for data extraction.

## ğŸŒŸ Features



- **Multiple Website Support**: Scrape data from 10+ popular websites
- **CSV Output**: All scrapers export data in CSV format for easy analysis
- **Easy to Use**: Simple Python scripts with clear documentation
- **Educational**: Perfect for learning web scraping techniques
- **Open Source**: Contribute and improve the collection

## ğŸš€ Quick Start

### Prerequisites

```bash
pip install requests beautifulsoup4 lxml
```

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/amolsr/web-scrapping.git
   cd web-scrapping
   ```

2. **Run any scraper**
   ```bash
   python "1. flipkart.py"
   ```

3. **Check the output**
   ```bash
   ls output/
   ```

## ğŸ“Š Sample Output

### IMDB Top Movies
```csv
Rank,Name,Year,Rating,Link,Director
1,The Shawshank Redemption,1994,9.2,https://www.imdb.com/title/tt0111161/,Frank Darabont
2,The Godfather,1972,9.2,https://www.imdb.com/title/tt0068646/,Francis Ford Coppola
```

### Flipkart Smartphones
```csv
Mobile Name,Ratings,Pricing,Description
Nokia 8.1,4.3,â‚¹15,999,6GB RAM | 128GB Storage
Nokia 6.1 Plus,4.2,â‚¹12,999,4GB RAM | 64GB Storage
```

## ğŸ› ï¸ Usage Examples

### Basic Usage
```python
# Run a specific scraper
python "4. imdb.py"

# The script will automatically:
# 1. Fetch data from the website
# 2. Parse the HTML content
# 3. Extract relevant information
# 4. Save to CSV file in the output/ directory
```

### Customization
Each script can be easily modified to:
- Change the target URL
- Extract different data fields
- Modify the output format
- Add error handling

## ğŸ“ Project Structure

```
web-scrapping/
â”œâ”€â”€ 1. flipkart.py          # Flipkart smartphone scraper
â”œâ”€â”€ 2. youtube.py           # YouTube video scraper
â”œâ”€â”€ 3. youtube_links.py     # YouTube links extractor
â”œâ”€â”€ 4. imdb.py              # IMDB top movies scraper
â”œâ”€â”€ 5. Amazon.py            # Amazon product scraper
â”œâ”€â”€ 6. Github.py            # GitHub repository scraper
â”œâ”€â”€ 7. Udemy.py             # Udemy course scraper
â”œâ”€â”€ 8. college_notice_scrapper.py  # College notices scraper
â”œâ”€â”€ 9. Sanfoundry.py        # Sanfoundry educational content
â”œâ”€â”€ 10. HackNews.py         # Hacker News GitHub posts
â”œâ”€â”€ weather.py              # Weather information scraper
â”œâ”€â”€ output/                 # Generated CSV files
â”‚   â”œâ”€â”€ flipkart.csv
â”‚   â”œâ”€â”€ imdb.csv
â”‚   â”œâ”€â”€ github.csv
â”‚   â””â”€â”€ ...
â””â”€â”€ README.md               # This file
```

## ğŸ”§ Dependencies

- **requests**: HTTP library for making web requests
- **beautifulsoup4**: HTML/XML parsing library
- **lxml**: XML and HTML processing library
- **csv**: Built-in CSV module for data export

## ğŸ¤ Contributing

We welcome contributions! Here's how you can help:

1. **Fork the repository**
2. **Create a new scraper** or improve existing ones
3. **Add proper documentation** and comments
4. **Test your changes**
5. **Submit a pull request**

### Contribution Ideas
- Add new website scrapers
- Improve error handling
- Add data validation
- Create web interface
- Add support for different output formats (JSON, XML)
- Implement rate limiting and respect robots.txt

## âš ï¸ Important Notes

- **Respect robots.txt**: Always check the website's robots.txt file
- **Rate Limiting**: Add delays between requests to be respectful
- **Terms of Service**: Ensure you comply with each website's terms
- **Data Usage**: Use scraped data responsibly and ethically

## ğŸ“ License

This project is open source and available under the [MIT License](LICENSE).

## ğŸ™ Acknowledgments

- Beautiful Soup for HTML parsing
- Requests library for HTTP handling
- All contributors who help improve this collection

## ğŸ“ Support

If you have questions or need help:
- Open an issue on GitHub
- Check the code comments for implementation details
- Review the output files for expected data format

---

**Happy Scraping! ğŸ•·ï¸âœ¨**

[![Stargazers over time](https://starchart.cc/amolsr/web-scrapping.svg?variant=adaptive)](https://starchart.cc/amolsr/web-scrapping)
