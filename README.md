# Web Scraping Collection ğŸ•·ï¸

A comprehensive collection of web scraping scripts for extracting data from popular websites. This project demonstrates various web scraping techniques using Python and provides ready-to-use scripts for data extraction.
<img width="1536" height="1024" alt="image" src="https://github.com/user-attachments/assets/f2518991-a261-4c67-95e3-43e09ff421c6" />


## ğŸŒŸ Features

- **Multiple Website Support**: Scrape data from 10+ popular websites
- **CSV Output**: All scrapers export data in CSV format for easy analysis
- **Easy to Use**: Simple Python scripts with clear documentation
- **Educational**: Perfect for learning web scraping techniques
- **Open Source**: Contribute and improve the collection

## ğŸš€ Quick Start

### Prerequisites

```bash
pip install requests beautifulsoup4 lxml
```

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/amolsr/web-scrapping.git
   cd web-scrapping
   ```

2. **Run any scraper**
   ```bash
   python scrapers/ecommerce/flipkart.py
   ```

3. **Check the output**
   ```bash
   ls output/
   ```

## ğŸ“Š Sample Output

### IMDB Top Movies
```csv
Rank,Name,Year,Rating,Link,Director
1,The Shawshank Redemption,1994,9.2,https://www.imdb.com/title/tt0111161/,Frank Darabont
2,The Godfather,1972,9.2,https://www.imdb.com/title/tt0068646/,Francis Ford Coppola
```

### Flipkart Smartphones
```csv
Mobile Name,Ratings,Pricing,Description
Nokia 8.1,4.3,â‚¹15,999,6GB RAM | 128GB Storage
Nokia 6.1 Plus,4.2,â‚¹12,999,4GB RAM | 64GB Storage
```

## ğŸ› ï¸ Usage Examples

### Basic Usage
```python
# Run a specific scraper
python scrapers/content/imdb.py

# The script will automatically:
# 1. Fetch data from the website
# 2. Parse the HTML content
# 3. Extract relevant information
# 4. Save to CSV file in the output/ directory
```

### Customization
Each script can be easily modified to:
- Change the target URL
- Extract different data fields
- Modify the output format
- Add error handling

## ğŸ“ Project Structure

```
web-scrapping/
â”œâ”€â”€ scrapers/               # All scraper scripts organized by category
â”‚   â”œâ”€â”€ ecommerce/          # E-commerce website scrapers
â”‚   â”‚   â”œâ”€â”€ flipkart.py     # Flipkart smartphone scraper
â”‚   â”‚   â”œâ”€â”€ amazon.py       # Amazon product scraper
â”‚   â”‚   â””â”€â”€ olx.py          # OLX listings scraper
â”‚   â”œâ”€â”€ job_boards/         # Job board scrapers
â”‚   â”‚   â”œâ”€â”€ indeed.py       # Indeed job listings
â”‚   â”‚   â”œâ”€â”€ naukri_jobs.py  # Naukri job listings
â”‚   â”‚   â”œâ”€â”€ apnajob.py      # ApnaJob listings
â”‚   â”‚   â”œâ”€â”€ jobhai.py       # JobHai listings
â”‚   â”‚   â”œâ”€â”€ welcome_to_the_jungle.py  # Welcome to the Jungle jobs
â”‚   â”‚   â””â”€â”€ craigslist_jobs.py  # Craigslist jobs
â”‚   â”œâ”€â”€ educational/       # Educational platform scrapers
â”‚   â”‚   â”œâ”€â”€ udemy.py        # Udemy course scraper
â”‚   â”‚   â”œâ”€â”€ sanfoundry.py   # Sanfoundry educational content
â”‚   â”‚   â”œâ”€â”€ college_notice_scraper.py  # College notices scraper
â”‚   â”‚   â”œâ”€â”€ javaguide.py    # Java Guide content
â”‚   â”‚   â””â”€â”€ indiabix_networking.py  # IndiaBix networking Q&A
â”‚   â”œâ”€â”€ social_media/       # Social media and developer platforms
â”‚   â”‚   â”œâ”€â”€ youtube.py       # YouTube video scraper
â”‚   â”‚   â”œâ”€â”€ youtube_links.py # YouTube links extractor
â”‚   â”‚   â”œâ”€â”€ reddit.py       # Reddit posts scraper
â”‚   â”‚   â”œâ”€â”€ hackernews.py   # Hacker News posts
â”‚   â”‚   â”œâ”€â”€ stack_overflow.py  # Stack Overflow questions
â”‚   â”‚   â””â”€â”€ github.py       # GitHub repository scraper
â”‚   â”œâ”€â”€ content/            # Content and media scrapers
â”‚   â”‚   â”œâ”€â”€ imdb.py         # IMDB top movies scraper
â”‚   â”‚   â”œâ”€â”€ books_toscrape.py  # Books.toscrape.com scraper
â”‚   â”‚   â”œâ”€â”€ quotes_toscrape.py  # Quotes to scrape
â”‚   â”‚   â”œâ”€â”€ wikipedia.py    # Wikipedia table scraper
â”‚   â”‚   â””â”€â”€ openlibrary_books.py  # Open Library books
â”‚   â”œâ”€â”€ misc/               # Miscellaneous scrapers
â”‚   â”‚   â”œâ”€â”€ coinmarketcap.py  # Cryptocurrency market data
â”‚   â”‚   â”œâ”€â”€ weather.py      # Weather information scraper
â”‚   â”‚   â”œâ”€â”€ craigslist_housing.py  # Craigslist housing
â”‚   â”‚   â””â”€â”€ syntaxminds.py  # SyntaxMinds content
â”‚   â””â”€â”€ utils/              # Utility functions
â”‚       â””â”€â”€ __init__.py     # Helper functions for scrapers
â”œâ”€â”€ output/                 # Generated CSV files
â”‚   â”œâ”€â”€ flipkart_latest_smartphones.csv
â”‚   â”œâ”€â”€ imdb.csv
â”‚   â”œâ”€â”€ github.csv
â”‚   â””â”€â”€ ...
â”œâ”€â”€ main.py                 # Main entry point
â””â”€â”€ README.md               # This file
```

## ğŸ”§ Dependencies

- **requests**: HTTP library for making web requests
- **beautifulsoup4**: HTML/XML parsing library
- **lxml**: XML and HTML processing library
- **csv**: Built-in CSV module for data export

## ğŸ¤ Contributing

We welcome contributions! Here's how you can help:

1. **Fork the repository**
2. **Create a new scraper** or improve existing ones
3. **Add proper documentation** and comments
4. **Test your changes**
5. **Submit a pull request**

### Contribution Ideas
- Add new website scrapers
- Improve error handling
- Add data validation
- Create web interface
- Add support for different output formats (JSON, XML)
- Implement rate limiting and respect robots.txt

## âš ï¸ Important Notes

- **Respect robots.txt**: Always check the website's robots.txt file
- **Rate Limiting**: Add delays between requests to be respectful
- **Terms of Service**: Ensure you comply with each website's terms
- **Data Usage**: Use scraped data responsibly and ethically

## ğŸ“ License

This project is open source and available under the [MIT License](LICENSE).

## ğŸ™ Acknowledgments

- Beautiful Soup for HTML parsing
- Requests library for HTTP handling
- All contributors who help improve this collection

## ğŸ“ Support

If you have questions or need help:
- Open an issue on GitHub
- Check the code comments for implementation details
- Review the output files for expected data format

---

**Happy Scraping! ğŸ•·ï¸âœ¨**

[![Stargazers over time](https://starchart.cc/amolsr/web-scrapping.svg?variant=adaptive)](https://starchart.cc/amolsr/web-scrapping)
